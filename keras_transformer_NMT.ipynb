{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "997f80fdf021493898aa27dc97a4737a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08828a899ff042c6aa98f3388be4d96a",
              "IPY_MODEL_85bed14dd6884c009e75379194fac2d5",
              "IPY_MODEL_704d2b990cc44dd88f2f71eec95ecee9"
            ],
            "layout": "IPY_MODEL_e2fca2ece95e466e97dfd4ea9f15c817"
          }
        },
        "08828a899ff042c6aa98f3388be4d96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea27d85064924316b1dc58dc7ac585c2",
            "placeholder": "​",
            "style": "IPY_MODEL_63e85241904a4fc5a6ee97dfd22fe094",
            "value": "Downloading builder script: 100%"
          }
        },
        "85bed14dd6884c009e75379194fac2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60df51b9948c4300b1301be9983b804e",
            "max": 8146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc3d10cfb084d4fa216ed35a9eb5b53",
            "value": 8146
          }
        },
        "704d2b990cc44dd88f2f71eec95ecee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de472545d3154e0c998ef34851f4fbbc",
            "placeholder": "​",
            "style": "IPY_MODEL_c460f22cc9804f2ba4f9b09cfee32cde",
            "value": " 8.15k/8.15k [00:00&lt;00:00, 408kB/s]"
          }
        },
        "e2fca2ece95e466e97dfd4ea9f15c817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea27d85064924316b1dc58dc7ac585c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e85241904a4fc5a6ee97dfd22fe094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60df51b9948c4300b1301be9983b804e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc3d10cfb084d4fa216ed35a9eb5b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de472545d3154e0c998ef34851f4fbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c460f22cc9804f2ba4f9b09cfee32cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7XoMHypthLX",
        "outputId": "f9b03feb-2947-4c04-e000-7459c7ad8733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2023.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from evaluate) (23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from evaluate) (4.65.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from evaluate) (2.25.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from evaluate) (1.4.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (4.9.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: xxhash, portalocker, multidict, frozenlist, dill, colorama, charset-normalizer, async-timeout, yarl, sacrebleu, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets, evaluate\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 charset-normalizer-3.1.0 colorama-0.4.6 datasets-2.10.1 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.13.2 multidict-6.0.4 multiprocess-0.70.14 portalocker-2.7.0 responses-0.18.0 sacrebleu-2.3.1 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "#Install Libraries\n",
        "!pip install evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMFCvSKY3jot",
        "outputId": "9af09c68-8d55-417d-f42d-874183902b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import libraries\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from google.colab import drive\n",
        "import evaluate\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYA4pkh78WAY"
      },
      "outputs": [],
      "source": [
        "#I uploaded a parallel Italian English dataset to google drive for training, the dataset can be found here: https://www.manythings.org/anki/\n",
        "text_file = \"/content/drive/MyDrive/ita-eng/ita.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y04G1ACJ5NsV"
      },
      "outputs": [],
      "source": [
        "#Function to read in data from the raw text file\n",
        "def get_data(data_file):\n",
        "  with open(data_file) as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    cleaned_lines = []\n",
        "    for line in lines:\n",
        "      #The first two fields of each line are the actual parallel sentences, so only grab those\n",
        "      cleaned_lines.append(line.split(\"\\t\")[:2])\n",
        "    #A blank line will be accidentally read so remove it\n",
        "    cleaned_lines.pop(-1)\n",
        "    return cleaned_lines\n",
        "\n",
        "#Import data\n",
        "raw_data = get_data(text_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O64YeKxx5_bs"
      },
      "outputs": [],
      "source": [
        "#Start and end of sentence tokens\n",
        "start_token = \"[sos]\"\n",
        "end_token = \"[eos]\"\n",
        "SRC_LANG = 'EN'\n",
        "TGT_LANG = \"IT\"\n",
        "\n",
        "#Function to generate a list of tuples containing the parallel sentences\n",
        "def generate_pairs(sentence_list):\n",
        "  sentence_pairs = []\n",
        "  for sentence in sentence_list:\n",
        "    en = sentence[0]\n",
        "    #Add the start and end tokens to the Italian sentences\n",
        "    it = start_token + \" \" + sentence[-1] + \" \" + end_token\n",
        "    sentence_pairs.append((en,it))\n",
        "  return sentence_pairs\n",
        "\n",
        "#Get the sentence pairs\n",
        "sentence_pairs = generate_pairs(raw_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-KckX-7AAq9"
      },
      "outputs": [],
      "source": [
        "#Shuffle data and split it into training, validation and test sets\n",
        "num_sent = len(sentence_pairs)\n",
        "random.shuffle(sentence_pairs)\n",
        "train_sent = sentence_pairs[:int(num_sent*0.8)]\n",
        "test_sent = sentence_pairs[int(num_sent*0.8):int(num_sent*0.9)]\n",
        "val_sent = sentence_pairs[int(num_sent*0.9):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF22k5DuEu68"
      },
      "outputs": [],
      "source": [
        "#Remove punctuation from the target sentences, this is just for this simple example\n",
        "strip_chars = string.punctuation\n",
        "#But keep brakets since the start and end tokens contain them\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "#Set up vocab size, sequence length and batch size\n",
        "vocab_size = 20000\n",
        "sequence_length = 40\n",
        "batch_size = 64\n",
        "\n",
        "#Standardization function for the Italian text vectorization (tokenizer)\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "#Set up text vectorization for English and Italian\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "ita_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "#Get individual lists of the English & Italian training sentences\n",
        "train_eng_texts = [pair[0] for pair in train_sent]\n",
        "train_ita_texts = [pair[1] for pair in train_sent]\n",
        "#Fit the text vectorizers\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "ita_vectorization.adapt(train_ita_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs2iht0rFdaw"
      },
      "outputs": [],
      "source": [
        "#Function to use when calling map on a dataset object (This and the make_dataset funtion were taken from tensorflow documentation and modified slightly)\n",
        "def format_dataset(eng, ita):\n",
        "    eng = eng_vectorization(eng)\n",
        "    ita = ita_vectorization(ita)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ita[:, :-1],}, ita[:, 1:])\n",
        "\n",
        "#Function to take the list parallel sentences for the train and validation datasets and convert them to a \n",
        "#tensorflow dataset object to be used in training.\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, ita_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    ita_texts = list(ita_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ita_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_sent)\n",
        "val_ds = make_dataset(val_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rxc-iU6GcCp"
      },
      "outputs": [],
      "source": [
        "#Set up transformer model classes (encoder, decoder, positional embeddding, this was just taken directly from tensorflow documentation)\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aUPs8g0GvV3"
      },
      "outputs": [],
      "source": [
        "#Set up actual model\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oJozl-NHCHV",
        "outputId": "5c81b87f-598f-47c4-cdb2-623ac19beb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   5130240     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 20000)  15529760    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,815,456\n",
            "Trainable params: 23,815,456\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 2.0442 - accuracy: 0.6399"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 590s 127ms/step - loss: 2.0442 - accuracy: 0.6399 - val_loss: 1.1445 - val_accuracy: 0.7480\n",
            "Epoch 2/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 1.1197 - accuracy: 0.7515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 553s 122ms/step - loss: 1.1197 - accuracy: 0.7515 - val_loss: 0.9036 - val_accuracy: 0.7810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.8987 - accuracy: 0.7817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 554s 122ms/step - loss: 0.8987 - accuracy: 0.7817 - val_loss: 0.8033 - val_accuracy: 0.7966\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.7996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 554s 122ms/step - loss: 0.7798 - accuracy: 0.7996 - val_loss: 0.7537 - val_accuracy: 0.8041\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.8117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 554s 122ms/step - loss: 0.7023 - accuracy: 0.8117 - val_loss: 0.7091 - val_accuracy: 0.8123\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.8208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 560s 123ms/step - loss: 0.6463 - accuracy: 0.8208 - val_loss: 0.6955 - val_accuracy: 0.8166\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.8282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 553s 122ms/step - loss: 0.6028 - accuracy: 0.8282 - val_loss: 0.6739 - val_accuracy: 0.8202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.8340"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 553s 122ms/step - loss: 0.5686 - accuracy: 0.8340 - val_loss: 0.6635 - val_accuracy: 0.8224\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - ETA: 0s - loss: 0.5410 - accuracy: 0.8387"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 552s 122ms/step - loss: 0.5410 - accuracy: 0.8387 - val_loss: 0.6614 - val_accuracy: 0.8241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.8434"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 553s 122ms/step - loss: 0.5158 - accuracy: 0.8434 - val_loss: 0.6496 - val_accuracy: 0.8265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.4974 - accuracy: 0.8467 - val_loss: 0.6559 - val_accuracy: 0.8258\n",
            "Epoch 12/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.4805 - accuracy: 0.8497 - val_loss: 0.6522 - val_accuracy: 0.8276\n",
            "Epoch 13/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.8525"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 552s 122ms/step - loss: 0.4658 - accuracy: 0.8525 - val_loss: 0.6479 - val_accuracy: 0.8293\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4536/4536 [==============================] - 549s 121ms/step - loss: 0.4530 - accuracy: 0.8550 - val_loss: 0.6539 - val_accuracy: 0.8292\n",
            "Epoch 15/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.8570"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 552s 122ms/step - loss: 0.4409 - accuracy: 0.8570 - val_loss: 0.6461 - val_accuracy: 0.8296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30\n",
            "4536/4536 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.8593"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4536/4536 [==============================] - 553s 122ms/step - loss: 0.4298 - accuracy: 0.8593 - val_loss: 0.6455 - val_accuracy: 0.8309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.4205 - accuracy: 0.8611 - val_loss: 0.6577 - val_accuracy: 0.8301\n",
            "Epoch 18/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.4133 - accuracy: 0.8625 - val_loss: 0.6564 - val_accuracy: 0.8306\n",
            "Epoch 19/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.4051 - accuracy: 0.8644 - val_loss: 0.6456 - val_accuracy: 0.8307\n",
            "Epoch 20/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.3995 - accuracy: 0.8655 - val_loss: 0.6528 - val_accuracy: 0.8299\n",
            "Epoch 21/30\n",
            "4536/4536 [==============================] - 542s 120ms/step - loss: 0.3923 - accuracy: 0.8666 - val_loss: 0.6547 - val_accuracy: 0.8325\n",
            "Epoch 22/30\n",
            "4536/4536 [==============================] - 549s 121ms/step - loss: 0.3881 - accuracy: 0.8675 - val_loss: 0.6601 - val_accuracy: 0.8309\n",
            "Epoch 23/30\n",
            "4536/4536 [==============================] - 550s 121ms/step - loss: 0.3821 - accuracy: 0.8689 - val_loss: 0.6661 - val_accuracy: 0.8301\n",
            "Epoch 24/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.3773 - accuracy: 0.8695 - val_loss: 0.6739 - val_accuracy: 0.8309\n",
            "Epoch 25/30\n",
            "4536/4536 [==============================] - 550s 121ms/step - loss: 0.3729 - accuracy: 0.8706 - val_loss: 0.6682 - val_accuracy: 0.8311\n",
            "Epoch 26/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.3692 - accuracy: 0.8714 - val_loss: 0.6648 - val_accuracy: 0.8307\n",
            "Epoch 27/30\n",
            "4536/4536 [==============================] - 550s 121ms/step - loss: 0.3652 - accuracy: 0.8721 - val_loss: 0.6739 - val_accuracy: 0.8309\n",
            "Epoch 28/30\n",
            "4536/4536 [==============================] - 550s 121ms/step - loss: 0.3612 - accuracy: 0.8730 - val_loss: 0.6703 - val_accuracy: 0.8311\n",
            "Epoch 29/30\n",
            "4536/4536 [==============================] - 544s 120ms/step - loss: 0.3573 - accuracy: 0.8739 - val_loss: 0.6746 - val_accuracy: 0.8309\n",
            "Epoch 30/30\n",
            "4536/4536 [==============================] - 543s 120ms/step - loss: 0.3562 - accuracy: 0.8739 - val_loss: 0.6732 - val_accuracy: 0.8314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11e01fd8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Train for 30 epochs\n",
        "epochs = 30\n",
        "\n",
        "#Will save the best model checkpoint during training\n",
        "checkpoint_folder = \"/content/drive/MyDrive/small_transformer_keras\"\n",
        "#Pick val_loss to determine which is the best model to checkpoint since accuracy is not a great metric\n",
        "callback = ModelCheckpoint(checkpoint_folder, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
        "\n",
        "#Call back list to pass for fit method\n",
        "callbacks_list = [callback]\n",
        "\n",
        "#Print summary, compile and train the model\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXO9FI910JQ0",
        "outputId": "42198ee7-993a-4a3e-fe3d-bc1af4971289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py:1564: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/saved_model/layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return serialization.serialize_keras_object(obj)\n"
          ]
        }
      ],
      "source": [
        "#Also save the final model after training just in case\n",
        "transformer.save(\"/content/drive/MyDrive/Final_keras_small_transformer\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_decoded_sentence_length = 40\n",
        "#Method to decode an input sentence and generate the translation\n",
        "def decode_sequence(input_sentence, transformer):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[sos]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ita_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        #Find the most likely next token and add it to the decoded sentence\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ita_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[eos]\":\n",
        "            break\n",
        "    #get rid of SOS and EOS tokens\n",
        "    decoded_sentence = decoded_sentence.replace(\"[sos] \",\"\")\n",
        "    decoded_sentence = decoded_sentence.replace(\" [eos]\",\"\")\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "hve-bYTFw0xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to simply get a list of all test labels, removing the SOS and EOS tokens to make it look cleaner\n",
        "def prepare_test_label(test_sent):\n",
        "  test_labels = []\n",
        "  for sent in test_sent:\n",
        "    label = sent[1]\n",
        "    label = label.replace(\"[sos] \",\"\")\n",
        "    label = label.replace(\" [eos]\",\"\")\n",
        "    test_labels.append(label)\n",
        "  return test_labels\n",
        "\n",
        "test_labels = prepare_test_label(test_sent)"
      ],
      "metadata": {
        "id": "1vo3Qse41U1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paq0BMfOhj18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "997f80fdf021493898aa27dc97a4737a",
            "08828a899ff042c6aa98f3388be4d96a",
            "85bed14dd6884c009e75379194fac2d5",
            "704d2b990cc44dd88f2f71eec95ecee9",
            "e2fca2ece95e466e97dfd4ea9f15c817",
            "ea27d85064924316b1dc58dc7ac585c2",
            "63e85241904a4fc5a6ee97dfd22fe094",
            "60df51b9948c4300b1301be9983b804e",
            "afc3d10cfb084d4fa216ed35a9eb5b53",
            "de472545d3154e0c998ef34851f4fbbc",
            "c460f22cc9804f2ba4f9b09cfee32cde"
          ]
        },
        "outputId": "d5003eb6-8f8a-477d-e983-05b651830d94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "997f80fdf021493898aa27dc97a4737a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu score on test set:  28.91200447679424\n"
          ]
        }
      ],
      "source": [
        "#Get the vocab from the Italian text vectorizer and set up a dictionary to look it up by index\n",
        "ita_vocab = ita_vectorization.get_vocabulary()\n",
        "ita_index_lookup = dict(zip(range(len(ita_vocab)), ita_vocab))\n",
        "\n",
        "#Function to generate the translations for the test set\n",
        "def translate_test_set(test_sent, transformer):\n",
        "  pred_test_translations = []\n",
        "  for sent in test_sent:\n",
        "    pred_translation = decode_sequence(sent[0],transformer)\n",
        "    pred_test_translations.append(pred_translation)\n",
        "  return pred_test_translations\n",
        "\n",
        "pred_test_translations = translate_test_set(test_sent, transformer)\n",
        "\n",
        "#Get the BLEU score on the test set\n",
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "results = bleu.compute(predictions=pred_test_translations, references=test_labels)\n",
        "print(\"Bleu score on test set: \", results[\"score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not too bad for English to Italian given the dataset and model used."
      ],
      "metadata": {
        "id": "2Q6KRW3fy2WE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49f38a6-a962-4323-ffdd-7fdb87514707",
        "id": "dW9NA4-ot0TG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example # 1\n",
            "Input English sentence:  Do you want anything, Tom?\n",
            "Predicted translation:  vuoi qualcosa\n",
            "Ground truth translation:  Vuoi qualcosa, Tom? \n",
            "\n",
            "Example # 2\n",
            "Input English sentence:  He has a flower in his hand.\n",
            "Predicted translation:  lui ha un fiore in mano\n",
            "Ground truth translation:  Ha un fiore in mano. \n",
            "\n",
            "Example # 3\n",
            "Input English sentence:  Tom followed the instructions.\n",
            "Predicted translation:  tom ha seguito le istruzioni\n",
            "Ground truth translation:  Tom ha seguito le istruzioni. \n",
            "\n",
            "Example # 4\n",
            "Input English sentence:  He said, \"It's nine o'clock.\"\n",
            "Predicted translation:  ha detto le nove\n",
            "Ground truth translation:  Ha detto: \"Sono le nove.\" \n",
            "\n",
            "Example # 5\n",
            "Input English sentence:  Tom has been studying French for about three years.\n",
            "Predicted translation:  tom ha studiato il francese per circa tre anni\n",
            "Ground truth translation:  Tom ha studiato francese per circa tre anni. \n",
            "\n",
            "Example # 6\n",
            "Input English sentence:  Circumstances did not permit me to help you.\n",
            "Predicted translation:  le circostanze non mi hanno permesso di aiutarti\n",
            "Ground truth translation:  Le circostanze non mi permisero di aiutarla. \n",
            "\n",
            "Example # 7\n",
            "Input English sentence:  Please leave the building.\n",
            "Predicted translation:  vattene dallo edificio\n",
            "Ground truth translation:  Per favore, lasciate l'edificio. \n",
            "\n",
            "Example # 8\n",
            "Input English sentence:  I'll come back this afternoon.\n",
            "Predicted translation:  tornerò questo pomeriggio\n",
            "Ground truth translation:  Tornerò questo pomeriggio. \n",
            "\n",
            "Example # 9\n",
            "Input English sentence:  Why don't you turn it off?\n",
            "Predicted translation:  perché non la spegnete\n",
            "Ground truth translation:  Perché non lo spegne? \n",
            "\n",
            "Example # 10\n",
            "Input English sentence:  Tom bought each of them a camera.\n",
            "Predicted translation:  tom ha comprato a ognuno di loro una macchina fotografica\n",
            "Ground truth translation:  Tom ha comprato a ognuno di loro una macchina fotografica. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Function to randomly sample 10 sentences from the test set and show the input sentence, predicted translation and actual translation \n",
        "#to get a general idea of how close the translations are\n",
        "def sample_test_translations(test_sent, transformer, test_labels):\n",
        "  prev_examples = []\n",
        "  max_index = len(test_sent)\n",
        "  for i in range(10):\n",
        "    sent_index = random.randint(0,max_index)\n",
        "    #Make sure examples aren't repeated\n",
        "    while sent_index in prev_examples:\n",
        "      sent_index = random.randint(0,max_index)\n",
        "    prev_examples.append(sent_index)\n",
        "    test_input = test_sent[sent_index][0]\n",
        "    test_label = test_labels[sent_index]\n",
        "    prediction = decode_sequence(test_input, transformer)\n",
        "    print(\"Example #\",str(i+1))\n",
        "    print(\"Input English sentence: \", test_input)\n",
        "    print(\"Predicted translation: \", prediction)\n",
        "    print(\"Ground truth translation: \",test_label,\"\\n\")\n",
        "\n",
        "sample_test_translations(test_sent, transformer, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So again, not perfect but not bad for the model and the dataset size (~362k parallel sentences), as well as the simple tokenization used."
      ],
      "metadata": {
        "id": "TT48zRTayTkx"
      }
    }
  ]
}